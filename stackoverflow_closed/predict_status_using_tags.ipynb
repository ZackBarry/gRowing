{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary spark functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._ \n",
    "import org.apache.spark.ml.feature._\n",
    "import org.apache.spark.ml.classification.{NaiveBayes,NaiveBayesModel,RandomForestClassifier}\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.expressions.Window\n",
    "import org.apache.spark.ml._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://kokes.github.io/blog/2018/05/19/spark-sane-csv-processing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customSchema = StructType(StructField(PostId,DoubleType,true), StructField(PostCreationDate,StringType,true), StructField(OwnerUserId,DoubleType,true), StructField(OwnerCreationDate,StringType,true), StructField(ReputationAtPostCreation,DoubleType,true), StructField(OwnerUndeletedAnswerCountAtPostTime,DoubleType,true), StructField(Title,StringType,true), StructField(BodyMarkdown,StringType,true), StructField(Tag1,StringType,true), StructField(Tag2,StringType,true), StructField(Tag3,StringType,true), StructField(Tag4,StringType,true), StructField(Tag5,StringType,true), StructField(PostClosedDate,StringType,true), StructField(OpenStatus,StringType,true))\n",
       "df = [PostId: double, PostCre...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PostId: double, PostCre..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types._\n",
    "\n",
    "val customSchema = StructType(Array(\n",
    "    StructField(\"PostId\", DoubleType, true),\n",
    "    StructField(\"PostCreationDate\", StringType, true),\n",
    "    StructField(\"OwnerUserId\", DoubleType, true),\n",
    "    StructField(\"OwnerCreationDate\", StringType, true),\n",
    "    StructField(\"ReputationAtPostCreation\", DoubleType, true),\n",
    "    StructField(\"OwnerUndeletedAnswerCountAtPostTime\", DoubleType, true),\n",
    "    StructField(\"Title\", StringType, true),\n",
    "    StructField(\"BodyMarkdown\", StringType, true),\n",
    "    StructField(\"Tag1\", StringType, true),\n",
    "    StructField(\"Tag2\", StringType, true),\n",
    "    StructField(\"Tag3\", StringType, true),\n",
    "    StructField(\"Tag4\", StringType, true),\n",
    "    StructField(\"Tag5\", StringType, true),\n",
    "    StructField(\"PostClosedDate\", StringType, true),\n",
    "    StructField(\"OpenStatus\", StringType, true)\n",
    "))\n",
    "\n",
    "var df = spark.\n",
    "    read.\n",
    "    option(\"quote\", \"\\\"\").\n",
    "    option(\"escape\", \"\\\"\").\n",
    "    option(\"multiLine\", \"true\").\n",
    "    option(\"header\", \"true\").\n",
    "    schema(customSchema).\n",
    "    csv(\"train-sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read sample of training data set in from S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6206ddd6e3ae4810b4ced27a856ccc81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import org.apache.spark.sql.types._\n",
      "customSchema: org.apache.spark.sql.types.StructType = StructType(StructField(PostId,DoubleType,true), StructField(PostCreationDate,StringType,true), StructField(OwnerUserId,DoubleType,true), StructField(OwnerCreationDate,StringType,true), StructField(ReputationAtPostCreation,DoubleType,true), StructField(OwnerUndeletedAnswerCountAtPostTime,DoubleType,true), StructField(Title,StringType,true), StructField(BodyMarkdown,StringType,true), StructField(Tag1,StringType,true), StructField(Tag2,StringType,true), StructField(Tag3,StringType,true), StructField(Tag4,StringType,true), StructField(Tag5,StringType,true), StructField(PostClosedDate,StringType,true), StructField(OpenStatus,StringType,true))\n",
      "df: org.apache.spark.sql.DataFrame = [PostId: double, PostCreationDate: string ... 13 more fields]\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.types._\n",
    "\n",
    "val customSchema = StructType(Array(\n",
    "    StructField(\"PostId\", DoubleType, true),\n",
    "    StructField(\"PostCreationDate\", StringType, true),\n",
    "    StructField(\"OwnerUserId\", DoubleType, true),\n",
    "    StructField(\"OwnerCreationDate\", StringType, true),\n",
    "    StructField(\"ReputationAtPostCreation\", DoubleType, true),\n",
    "    StructField(\"OwnerUndeletedAnswerCountAtPostTime\", DoubleType, true),\n",
    "    StructField(\"Title\", StringType, true),\n",
    "    StructField(\"BodyMarkdown\", StringType, true),\n",
    "    StructField(\"Tag1\", StringType, true),\n",
    "    StructField(\"Tag2\", StringType, true),\n",
    "    StructField(\"Tag3\", StringType, true),\n",
    "    StructField(\"Tag4\", StringType, true),\n",
    "    StructField(\"Tag5\", StringType, true),\n",
    "    StructField(\"PostClosedDate\", StringType, true),\n",
    "    StructField(\"OpenStatus\", StringType, true)\n",
    "))\n",
    "\n",
    "var df = spark.\n",
    "    read.\n",
    "    option(\"quote\", \"\\\"\").\n",
    "    option(\"escape\", \"\\\"\").\n",
    "    option(\"multiLine\", \"true\").\n",
    "    option(\"header\", \"true\").\n",
    "    schema(customSchema).\n",
    "    csv(\"s3://stackoverflow-kaggle/data/train-sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+-----------+-------------------+------------------------+-----------------------------------+--------------------+--------------------+---------------+-----------------+-------------+------------------+----------+-------------------+--------------------+\n",
      "|     PostId|   PostCreationDate|OwnerUserId|  OwnerCreationDate|ReputationAtPostCreation|OwnerUndeletedAnswerCountAtPostTime|               Title|        BodyMarkdown|           Tag1|             Tag2|         Tag3|              Tag4|      Tag5|     PostClosedDate|          OpenStatus|\n",
      "+-----------+-------------------+-----------+-------------------+------------------------+-----------------------------------+--------------------+--------------------+---------------+-----------------+-------------+------------------+----------+-------------------+--------------------+\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "+-----------+-------------------+-----------+-------------------+------------------------+-----------------------------------+--------------------+--------------------+---------------+-----------------+-------------+------------------+----------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `OpenStatus` column seems to have an issue with trailing whitespace -- there should be a column ending pipe operator `|` in the printed table above.  Using `trim` didn't work, so we're taking a regex approach instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df = [PostId: double, PostCreationDate: string ... 13 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PostId: double, PostCreationDate: string ... 13 more fields]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.withColumn(\"OpenStatus\", regexp_extract(col(\"OpenStatus\"), \"([\\\\w\\\\s]+\\\\w)\", 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the percentage of null values for each column -- Tag2, Tag3, and Tag4 are the only columns with a significant amount of missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+-----------+-----------------+------------------------+-----------------------------------+-----+------------+--------------------+-------------------+-------------------+------------------+------------------+--------------+----------+\n",
      "|PostId|PostCreationDate|OwnerUserId|OwnerCreationDate|ReputationAtPostCreation|OwnerUndeletedAnswerCountAtPostTime|Title|BodyMarkdown|                Tag1|               Tag2|               Tag3|              Tag4|              Tag5|PostClosedDate|OpenStatus|\n",
      "+------+----------------+-----------+-----------------+------------------------+-----------------------------------+-----+------------+--------------------+-------------------+-------------------+------------------+------------------+--------------+----------+\n",
      "|   0.0|             0.0|        0.0|              0.0|                     0.0|                                0.0|  0.0|         0.0|7.129006501653929E-6|0.19408720200752824|0.45855195619938405|0.7172208281053952|0.8879534048135052|           0.5|       0.0|\n",
      "+------+----------------+-----------+-----------------+------------------------+-----------------------------------+-----+------------+--------------------+-------------------+-------------------+------------------+------------------+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.\n",
    "    select(df.columns.map(c => (sum(when(col(c).isNull || col(c) === \"\" || col(c).isNaN, 1).otherwise(0)) / df.count()).alias(c)): _*).\n",
    "    show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the `Tag` fields with \"unknown\" so they can be processed as categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df = [PostId: double, PostCreationDate: string ... 13 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PostId: double, PostCreationDate: string ... 13 more fields]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.na.fill(\"unknown\", Seq(\"Tag1\", \"Tag2\", \"Tag3\", \"Tag4\", \"Tag5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple model: Naive Bayes with Tags as features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with, we'll take a simple approach - encode the Tag columns as categorical variables and predict `OpenStatus` using Random Forest. Spark's RF Classifier example will serve as a reference ([link](https://github.com/apache/spark/blob/master/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_simple = [Tag1: string, Tag2: string ... 4 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Tag1: string, Tag2: string ... 4 more fields]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df_simple = df.\n",
    "    select(col(\"Tag1\"), col(\"Tag2\"), col(\"Tag3\"), col(\"Tag4\"), col(\"Tag5\"), col(\"OpenStatus\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA - frequency of `OpenStatus` and `TagX`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the label `OpenStatus` has only 5 distinct values while each of the tags has over 5000 distinct values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct Tag1 values: 5212\n",
      "Distinct Tag2 values: 9295\n",
      "Distinct Tag3 values: 11083\n",
      "Distinct Tag4 values: 10030\n",
      "Distinct Tag5 values: 7607\n",
      "Distinct OpenStatus values: 5\n"
     ]
    }
   ],
   "source": [
    "df_simple.\n",
    "    columns.\n",
    "    map(c => {\n",
    "            val count = df_simple.select(c).distinct.count\n",
    "            f\"Distinct $c values: $count\"\n",
    "    }).\n",
    "    foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`OpenStatus` takes on the value `open` in exactly 50% of all cases.  The category `too localized` appears least often at 4.4% of occurrences.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+------------------+\n",
      "|         OpenStatus|count|     perc_of_total|\n",
      "+-------------------+-----+------------------+\n",
      "|               open|70136|              50.0|\n",
      "|not a real question|30789|21.949498117942284|\n",
      "|          off topic|17530|12.497148397399338|\n",
      "|   not constructive|15659|11.163311280939888|\n",
      "|      too localized| 6158| 4.390042203718489|\n",
      "+-------------------+-----+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "status_counts = [OpenStatus: string, count: bigint ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[OpenStatus: string, count: bigint ... 1 more field]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val status_counts = df_simple.\n",
    "    groupBy(\"OpenStatus\").\n",
    "    count().\n",
    "    sort(col(\"count\").desc).\n",
    "    withColumn(\"perc_of_total\", lit(100) * col(\"count\") / df_simple.count())\n",
    "\n",
    "status_counts.show(numRows = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To cut down on the number of distinct `TagX` values, we'll try keeping the top 90% of observations.  The bottom 10% will be replaced with \"other\".  Below we count the number of distinct tags in the top 90% of observations for each `TagX` column.  `Tag2` and `Tag3` still have over 500 distinct values, but this is far less than the 10,000+ values they originally had."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_percentile_count: (df: org.apache.spark.sql.DataFrame, percentile: Double)(col_name: String)Double\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array(108.0, 689.0, 973.0, 350.0, 0.0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_percentile_count(df: DataFrame, percentile: Double)(col_name: String): Double = {\n",
    "    \n",
    "    val cumsum_window = Window.\n",
    "      orderBy(col(\"count\").desc).\n",
    "      rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "    val total_window = Window.\n",
    "        rowsBetween(Window.unboundedPreceding, Window.unboundedFollowing)\n",
    "    \n",
    "    df.\n",
    "        groupBy(col_name).\n",
    "        count().\n",
    "        orderBy(col(\"count\").desc).\n",
    "        withColumn(\"fracObs\", sum(col(\"count\")).over(cumsum_window) / sum(col(\"count\")).over(total_window)).\n",
    "        filter(col(\"fracObs\") <= percentile).\n",
    "        count()\n",
    "}\n",
    "\n",
    "Array(\"Tag1\", \"Tag2\", \"Tag3\", \"Tag4\", \"Tag5\").\n",
    "    map(get_percentile_count(df_simple, 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline for Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are null `Tag1` values, we use `setHandleInvalid(\"keep\")` so that they are indexed rather than dropped ([so_link](https://stackoverflow.com/a/36113473))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create a StringIndexer for each Tag column; rather than create 5 variables we'll take a functional approach.  Note that `setHandleInvalid` is set to \"keep\" so that the indexer adds new indexes when it sees new labels in data sets other than our current data set ([StackOverflow link](https://stackoverflow.com/a/43917703/11407644))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "featureCols = Array(Tag1, Tag2, Tag3, Tag4, Tag5)\n",
       "featureIndexers = Array(strIdx_611619faad8a, strIdx_cb5e9c7716c2, strIdx_cfcab24b941c, strIdx_410970f4bcd3, strIdx_77761dfab371)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array(strIdx_611619faad8a, strIdx_cb5e9c7716c2, strIdx_cfcab24b941c, strIdx_410970f4bcd3, strIdx_77761dfab371)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val featureCols = Array[String](\"Tag1\", \"Tag2\", \"Tag3\", \"Tag4\", \"Tag5\")\n",
    "\n",
    "val featureIndexers = featureCols.map { colName =>\n",
    "    new StringIndexer().\n",
    "        setInputCol(colName).\n",
    "        setOutputCol(\"indexed\" + colName).\n",
    "        setHandleInvalid(\"keep\").\n",
    "        fit(df_simple)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark ML models expect a feature vector to be the only predictor.  [`VectorAssembler`](https://spark.apache.org/docs/latest/ml-features.html#vectorassembler) is a transformer that combines a list of columns into a single vector column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assembler = vecAssembler_1d91282ebf85\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vecAssembler_1d91282ebf85"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val assembler = new VectorAssembler().\n",
    "    setInputCols(featureCols.map{x => \"indexed\" + x}).\n",
    "    setOutputCol(\"features\").\n",
    "    setHandleInvalid(\"keep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as with the categorical features, we index the response.  Keeping with convention, the indexed response is called `indexedLabel` rather than `indexedOpenStatus`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labelIndexer = strIdx_b539aaa6ac67\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "strIdx_b539aaa6ac67"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val labelIndexer = new StringIndexer().\n",
    "    setInputCol(\"OpenStatus\").\n",
    "    setOutputCol(\"indexedLabel\").\n",
    "    setHandleInvalid(\"keep\").\n",
    "    fit(df_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the response is indexed, we need a way to transform the predicted response back to its original string value.  This inverse transformer is called [`IndexToString`](https://spark.apache.org/docs/latest/ml-features.html#indextostring):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labelConverter = idxToStr_aaba441fd44a\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "idxToStr_aaba441fd44a"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val labelConverter = new IndexToString().\n",
    "    setInputCol(\"prediction\").\n",
    "    setOutputCol(\"predictionLabel\").\n",
    "    setLabels(labelIndexer.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can specify our model, multinomial [NaiveBayes](https://spark.apache.org/docs/latest/mllib-naive-bayes.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nb = nb_b39000a2c562\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nb_b39000a2c562"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val nb = new NaiveBayes().\n",
    "    setLabelCol(\"label\").\n",
    "    setFeaturesCol(\"features\").\n",
    "    setSmoothing(1.0).\n",
    "    setModelType(\"multinomial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline is constructed by combining the feature indexers built for each of the `TagX` variables with the vector assember, label index, and model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nb_pipeline = pipeline_300358b41c3d\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_300358b41c3d"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val nb_pipeline = new Pipeline().\n",
    "    setStages(featureIndexers ++ Array(assembler, labelIndexer, nb, labelConverter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can specify our model, a [`RandomForestClassifer`](https://spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-classifier):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe20f2a3e35441efa484a05034bce0b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf: org.apache.spark.ml.classification.RandomForestClassifier = rfc_9df6a58d40ea\n"
     ]
    }
   ],
   "source": [
    "val rf = new RandomForestClassifier().\n",
    "    setLabelCol(\"label\").\n",
    "    setFeaturesCol(\"features\").\n",
    "    setNumTrees(10).\n",
    "    setMaxBins(12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b925ac37d2a4dd28c5874f873c5d16f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline: org.apache.spark.ml.Pipeline = pipeline_b75699e47b54\n"
     ]
    }
   ],
   "source": [
    "val rf_pipeline = new Pipeline().\n",
    "    setStages(featureIndexers ++ Array(assembler, labelIndexer, rf, labelConverter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train = [Tag1: string, Tag2: string ... 4 more fields]\n",
       "test = [Tag1: string, Tag2: string ... 4 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Tag1: string, Tag2: string ... 4 more fields]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Array(train, test) = df_simple.randomSplit(Array(0.7, 0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the pipeline to the training set to create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+--------------------+\n",
      "|predictionLabel|label|            features|\n",
      "+---------------+-----+--------------------+\n",
      "|      off topic|  0.0|    (5,[0],[3312.0])|\n",
      "|      off topic|  0.0|[75.0,552.0,619.0...|\n",
      "|  too localized|  0.0|[75.0,285.0,504.0...|\n",
      "|           open|  2.0|[75.0,342.0,10612...|\n",
      "|      off topic|  0.0|(5,[0,1],[75.0,23...|\n",
      "+---------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model = pipeline_300358b41c3d\n",
       "predictions = [Tag1: string, Tag2: string ... 15 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Tag1: string, Tag2: string ... 15 more fields]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val model = nb_pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val predictions = model.transform(test)\n",
    "predictions.select(\"predictionLabel\", \"OpenStatus\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up [MulticlassClassificationEvaluator](https://spark.apache.org/docs/2.3.0/api/scala/index.html#org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluator = mcEval_28b51846e9f0\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "mcEval_28b51846e9f0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val evaluator = new MulticlassClassificationEvaluator()\n",
    "    .setLabelCol(\"label\")\n",
    "    .setPredictionCol(\"prediction\")\n",
    "    .setMetricName(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our accuracy was ~27%.  To get a sense for how good or bad this is, let's look at how well the model would have performed if it simply guessed the most common response (`Open`) each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy = 0.27433144919963903\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.27433144919963903"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val accuracy = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+------------------+\n",
      "|         OpenStatus|count|     perc_of_total|\n",
      "+-------------------+-----+------------------+\n",
      "|not a real question| 9334|22.167862062413906|\n",
      "|      too localized| 1842| 4.374673443214744|\n",
      "|   not constructive| 4692|11.143304992162637|\n",
      "|          off topic| 5274|12.525530803210943|\n",
      "|               open|20964| 49.78862869899777|\n",
      "+-------------------+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.\n",
    "    groupBy(\"OpenStatus\").\n",
    "    count().\n",
    "    withColumn(\"perc_of_total\", lit(100) * col(\"count\") / lit(predictions.count())).\n",
    "    show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the model had guessed `open` for each test observation, the accuracy would have been 49.8% -- much higher than the 27% that NaiveBayes achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|         OpenStatus|           accurracy|\n",
      "+-------------------+--------------------+\n",
      "|not a real question|0.030319262909792158|\n",
      "|      too localized| 0.05863192182410423|\n",
      "|   not constructive|0.017263427109974423|\n",
      "|          off topic|   0.586841107318923|\n",
      "|               open|  0.3808433505056287|\n",
      "+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.\n",
    "    select(\"predictionLabel\", \"OpenStatus\").\n",
    "    withColumn(\"success\", when(col(\"predictionLabel\") === col(\"OpenStatus\"), 1).otherwise(0)).\n",
    "    groupBy(\"OpenStatus\").\n",
    "    agg((sum(col(\"success\")) / count(\"*\")).alias(\"accurracy\")).\n",
    "    show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A look at class-specific performance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
